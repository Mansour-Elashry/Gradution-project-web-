{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "\n",
    "from IPython.display import Image, HTML\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare path\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Image size\n",
    "\n",
    "IMAGE_SIZE = (48,48)\n",
    "IMAGE_SHAPE = IMAGE_SIZE + (3,)\n",
    "\n",
    "BS = 64\n",
    "EPOCHS = 125\n",
    "ADAM_LEARNING_RATE = 0.0001\n",
    "PATIENCE =10\n",
    "\n",
    "classes=['Angry','Disgust','Fear','Happy','Neutral','Sad','Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   featurewise_center=False,\n",
    "                                   featurewise_std_normalization=False,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load datasat\n",
    "\n",
    "train_dataset  = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                   target_size = IMAGE_SIZE,\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   batch_size = BS)\n",
    "\n",
    "test_dataset = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                  target_size = IMAGE_SIZE,\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  shuffle =True,\n",
    "                                                  batch_size = BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data labels\n",
    "\n",
    "class_labels = test_dataset.class_indices\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "# See the shape of any data\n",
    "\n",
    "train_sample=next(train_dataset)\n",
    "print(train_sample[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 24, 24, 32)        864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 24, 24, 32)       128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 24, 24, 32)       288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 24, 24, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 24, 24, 64)        2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 24, 24, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 12, 12, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 12, 12, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 12, 12, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 12, 12, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 12, 12, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 12, 12, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 12, 12, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 12, 12, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 13, 13, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 6, 6, 128)        1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 6, 6, 128)        512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 6, 6, 256)         32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 6, 6, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 6, 6, 256)        2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 6, 6, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 6, 6, 256)         65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 6, 6, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 3, 3, 256)        2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 3, 3, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 3, 3, 512)         131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 3, 3, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 3, 3, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 3, 3, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 3, 3, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 3, 3, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 3, 3, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 3, 3, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 3, 3, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 3, 3, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 3, 3, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 3, 3, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 3, 3, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 3, 3, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 3, 3, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 3, 3, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 3, 3, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 3, 3, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 3, 3, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 3, 3, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 3, 3, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 3, 3, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 4, 4, 512)        0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 1, 1, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 1, 1, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 1, 1, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 1, 1, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 1, 1, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 1, 1, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Mobinet\n",
    "\n",
    "base_model = tf.keras.applications.MobileNet(input_shape=IMAGE_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing Layers\n",
    "\n",
    "for layer in base_model.layers[:-9]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trainable 86\n"
     ]
    }
   ],
   "source": [
    "print(\"Model trainable\",len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trainable 9\n"
     ]
    }
   ],
   "source": [
    "# Model trainable\n",
    "\n",
    "print(\"Model trainable\",len(base_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_1.00_224 (Functio  (None, 1, 1, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,526,599\n",
      "Trainable params: 1,885,191\n",
      "Non-trainable params: 1,641,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build transfer learning Model\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.001),bias_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.001),bias_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),  \n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      f1_score,\n",
    "]\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=ADAM_LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy',metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "449/449 [==============================] - 113s 252ms/step - loss: 4.3523 - accuracy: 0.8364 - precision: 0.3074 - recall: 0.1156 - auc: 0.6263 - f1_score: 0.1675 - val_loss: 2.3896 - val_accuracy: 0.8559 - val_precision: 0.4871 - val_recall: 0.1654 - val_auc: 0.7099 - val_f1_score: 0.2490 - lr: 1.0000e-04\n",
      "Epoch 2/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 4.0876 - accuracy: 0.8435 - precision: 0.3513 - recall: 0.1131 - auc: 0.6494 - f1_score: 0.1704 - val_loss: 2.3704 - val_accuracy: 0.8548 - val_precision: 0.4732 - val_recall: 0.1478 - val_auc: 0.7119 - val_f1_score: 0.2235 - lr: 1.0000e-04\n",
      "Epoch 3/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 3.9164 - accuracy: 0.8471 - precision: 0.3826 - recall: 0.1145 - auc: 0.6688 - f1_score: 0.1755 - val_loss: 2.2384 - val_accuracy: 0.8633 - val_precision: 0.5741 - val_recall: 0.1656 - val_auc: 0.7455 - val_f1_score: 0.2549 - lr: 1.0000e-04\n",
      "Epoch 4/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 3.7933 - accuracy: 0.8504 - precision: 0.4175 - recall: 0.1197 - auc: 0.6825 - f1_score: 0.1853 - val_loss: 2.2373 - val_accuracy: 0.8613 - val_precision: 0.5470 - val_recall: 0.1679 - val_auc: 0.7468 - val_f1_score: 0.2555 - lr: 1.0000e-04\n",
      "Epoch 5/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 3.6893 - accuracy: 0.8533 - precision: 0.4523 - recall: 0.1269 - auc: 0.6979 - f1_score: 0.1975 - val_loss: 2.1818 - val_accuracy: 0.8653 - val_precision: 0.5970 - val_recall: 0.1758 - val_auc: 0.7604 - val_f1_score: 0.2701 - lr: 1.0000e-04\n",
      "Epoch 6/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 3.6114 - accuracy: 0.8562 - precision: 0.4881 - recall: 0.1353 - auc: 0.7102 - f1_score: 0.2111 - val_loss: 2.1530 - val_accuracy: 0.8655 - val_precision: 0.5980 - val_recall: 0.1780 - val_auc: 0.7686 - val_f1_score: 0.2727 - lr: 1.0000e-04\n",
      "Epoch 7/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 3.5357 - accuracy: 0.8562 - precision: 0.4888 - recall: 0.1368 - auc: 0.7196 - f1_score: 0.2128 - val_loss: 2.1138 - val_accuracy: 0.8661 - val_precision: 0.6103 - val_recall: 0.1734 - val_auc: 0.7781 - val_f1_score: 0.2717 - lr: 1.0000e-04\n",
      "Epoch 8/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 3.4732 - accuracy: 0.8581 - precision: 0.5122 - recall: 0.1446 - auc: 0.7249 - f1_score: 0.2245 - val_loss: 2.1022 - val_accuracy: 0.8675 - val_precision: 0.6222 - val_recall: 0.1840 - val_auc: 0.7796 - val_f1_score: 0.2816 - lr: 1.0000e-04\n",
      "Epoch 9/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 3.4188 - accuracy: 0.8590 - precision: 0.5229 - recall: 0.1466 - auc: 0.7373 - f1_score: 0.2282 - val_loss: 2.0988 - val_accuracy: 0.8674 - val_precision: 0.6160 - val_recall: 0.1904 - val_auc: 0.7802 - val_f1_score: 0.2893 - lr: 1.0000e-04\n",
      "Epoch 10/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 3.3795 - accuracy: 0.8599 - precision: 0.5341 - recall: 0.1489 - auc: 0.7419 - f1_score: 0.2321 - val_loss: 2.1964 - val_accuracy: 0.8571 - val_precision: 0.4993 - val_recall: 0.1590 - val_auc: 0.7533 - val_f1_score: 0.2384 - lr: 1.0000e-04\n",
      "Epoch 11/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 3.3021 - accuracy: 0.8613 - precision: 0.5518 - recall: 0.1532 - auc: 0.7528 - f1_score: 0.2390 - val_loss: 2.1073 - val_accuracy: 0.8632 - val_precision: 0.5718 - val_recall: 0.1680 - val_auc: 0.7750 - val_f1_score: 0.2574 - lr: 1.0000e-04\n",
      "Epoch 12/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 3.2634 - accuracy: 0.8621 - precision: 0.5621 - recall: 0.1584 - auc: 0.7570 - f1_score: 0.2462 - val_loss: 2.0023 - val_accuracy: 0.8708 - val_precision: 0.6701 - val_recall: 0.1888 - val_auc: 0.8035 - val_f1_score: 0.2936 - lr: 1.0000e-04\n",
      "Epoch 13/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 3.2178 - accuracy: 0.8638 - precision: 0.5811 - recall: 0.1661 - auc: 0.7638 - f1_score: 0.2574 - val_loss: 2.0531 - val_accuracy: 0.8666 - val_precision: 0.6084 - val_recall: 0.1865 - val_auc: 0.7880 - val_f1_score: 0.2819 - lr: 1.0000e-04\n",
      "Epoch 14/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 3.1689 - accuracy: 0.8641 - precision: 0.5851 - recall: 0.1671 - auc: 0.7686 - f1_score: 0.2590 - val_loss: 2.0074 - val_accuracy: 0.8692 - val_precision: 0.6431 - val_recall: 0.1900 - val_auc: 0.7988 - val_f1_score: 0.2891 - lr: 1.0000e-04\n",
      "Epoch 15/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 3.1442 - accuracy: 0.8648 - precision: 0.5926 - recall: 0.1704 - auc: 0.7729 - f1_score: 0.2638 - val_loss: 1.9900 - val_accuracy: 0.8701 - val_precision: 0.6423 - val_recall: 0.2047 - val_auc: 0.8014 - val_f1_score: 0.3087 - lr: 1.0000e-04\n",
      "Epoch 16/125\n",
      "449/449 [==============================] - 55s 123ms/step - loss: 3.1088 - accuracy: 0.8656 - precision: 0.6000 - recall: 0.1766 - auc: 0.7791 - f1_score: 0.2718 - val_loss: 1.9768 - val_accuracy: 0.8706 - val_precision: 0.6515 - val_recall: 0.2028 - val_auc: 0.8043 - val_f1_score: 0.3085 - lr: 1.0000e-04\n",
      "Epoch 17/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 3.0659 - accuracy: 0.8663 - precision: 0.6081 - recall: 0.1805 - auc: 0.7842 - f1_score: 0.2774 - val_loss: 2.0171 - val_accuracy: 0.8644 - val_precision: 0.5834 - val_recall: 0.1779 - val_auc: 0.7914 - val_f1_score: 0.2702 - lr: 1.0000e-04\n",
      "Epoch 18/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 3.0447 - accuracy: 0.8667 - precision: 0.6138 - recall: 0.1796 - auc: 0.7873 - f1_score: 0.2767 - val_loss: 1.9639 - val_accuracy: 0.8684 - val_precision: 0.6160 - val_recall: 0.2094 - val_auc: 0.8048 - val_f1_score: 0.3108 - lr: 1.0000e-04\n",
      "Epoch 19/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 2.9914 - accuracy: 0.8679 - precision: 0.6239 - recall: 0.1897 - auc: 0.7910 - f1_score: 0.2902 - val_loss: 1.8757 - val_accuracy: 0.8747 - val_precision: 0.6904 - val_recall: 0.2230 - val_auc: 0.8260 - val_f1_score: 0.3339 - lr: 1.0000e-04\n",
      "Epoch 20/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.9579 - accuracy: 0.8679 - precision: 0.6219 - recall: 0.1920 - auc: 0.7952 - f1_score: 0.2922 - val_loss: 1.9009 - val_accuracy: 0.8719 - val_precision: 0.6693 - val_recall: 0.2044 - val_auc: 0.8172 - val_f1_score: 0.3118 - lr: 1.0000e-04\n",
      "Epoch 21/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 2.9417 - accuracy: 0.8689 - precision: 0.6317 - recall: 0.1976 - auc: 0.7983 - f1_score: 0.2998 - val_loss: 1.8900 - val_accuracy: 0.8734 - val_precision: 0.6745 - val_recall: 0.2203 - val_auc: 0.8176 - val_f1_score: 0.3296 - lr: 1.0000e-04\n",
      "Epoch 22/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.9072 - accuracy: 0.8688 - precision: 0.6298 - recall: 0.1985 - auc: 0.8016 - f1_score: 0.3010 - val_loss: 1.8770 - val_accuracy: 0.8728 - val_precision: 0.6674 - val_recall: 0.2191 - val_auc: 0.8192 - val_f1_score: 0.3297 - lr: 1.0000e-04\n",
      "Epoch 23/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.8778 - accuracy: 0.8699 - precision: 0.6432 - recall: 0.2012 - auc: 0.8061 - f1_score: 0.3052 - val_loss: 1.8756 - val_accuracy: 0.8721 - val_precision: 0.6525 - val_recall: 0.2242 - val_auc: 0.8180 - val_f1_score: 0.3319 - lr: 1.0000e-04\n",
      "Epoch 24/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.8372 - accuracy: 0.8709 - precision: 0.6471 - recall: 0.2116 - auc: 0.8101 - f1_score: 0.3181 - val_loss: 1.8237 - val_accuracy: 0.8747 - val_precision: 0.6780 - val_recall: 0.2343 - val_auc: 0.8289 - val_f1_score: 0.3455 - lr: 1.0000e-04\n",
      "Epoch 25/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.8150 - accuracy: 0.8703 - precision: 0.6385 - recall: 0.2127 - auc: 0.8109 - f1_score: 0.3182 - val_loss: 1.8297 - val_accuracy: 0.8739 - val_precision: 0.6648 - val_recall: 0.2360 - val_auc: 0.8260 - val_f1_score: 0.3459 - lr: 1.0000e-04\n",
      "Epoch 26/125\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 2.7924 - accuracy: 0.8714 - precision: 0.6494 - recall: 0.2175 - auc: 0.8150 - f1_score: 0.3250 - val_loss: 1.8718 - val_accuracy: 0.8698 - val_precision: 0.6250 - val_recall: 0.2211 - val_auc: 0.8143 - val_f1_score: 0.3258 - lr: 1.0000e-04\n",
      "Epoch 27/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.7800 - accuracy: 0.8710 - precision: 0.6433 - recall: 0.2173 - auc: 0.8163 - f1_score: 0.3239 - val_loss: 1.8300 - val_accuracy: 0.8723 - val_precision: 0.6479 - val_recall: 0.2328 - val_auc: 0.8220 - val_f1_score: 0.3420 - lr: 1.0000e-04\n",
      "Epoch 28/125\n",
      "449/449 [==============================] - 55s 121ms/step - loss: 2.7515 - accuracy: 0.8713 - precision: 0.6459 - recall: 0.2195 - auc: 0.8165 - f1_score: 0.3265 - val_loss: 1.8780 - val_accuracy: 0.8680 - val_precision: 0.6109 - val_recall: 0.2095 - val_auc: 0.8097 - val_f1_score: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 29/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.7074 - accuracy: 0.8724 - precision: 0.6566 - recall: 0.2243 - auc: 0.8211 - f1_score: 0.3333 - val_loss: 1.8060 - val_accuracy: 0.8732 - val_precision: 0.6654 - val_recall: 0.2258 - val_auc: 0.8246 - val_f1_score: 0.3337 - lr: 1.0000e-04\n",
      "Epoch 30/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.6810 - accuracy: 0.8736 - precision: 0.6624 - recall: 0.2352 - auc: 0.8255 - f1_score: 0.3460 - val_loss: 1.7541 - val_accuracy: 0.8759 - val_precision: 0.6954 - val_recall: 0.2340 - val_auc: 0.8354 - val_f1_score: 0.3502 - lr: 1.0000e-04\n",
      "Epoch 31/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.6662 - accuracy: 0.8735 - precision: 0.6580 - recall: 0.2380 - auc: 0.8262 - f1_score: 0.3484 - val_loss: 1.8064 - val_accuracy: 0.8733 - val_precision: 0.6496 - val_recall: 0.2451 - val_auc: 0.8222 - val_f1_score: 0.3545 - lr: 1.0000e-04\n",
      "Epoch 32/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.6504 - accuracy: 0.8732 - precision: 0.6558 - recall: 0.2372 - auc: 0.8267 - f1_score: 0.3471 - val_loss: 1.7789 - val_accuracy: 0.8734 - val_precision: 0.6496 - val_recall: 0.2474 - val_auc: 0.8269 - val_f1_score: 0.3581 - lr: 1.0000e-04\n",
      "Epoch 33/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.6417 - accuracy: 0.8744 - precision: 0.6672 - recall: 0.2412 - auc: 0.8272 - f1_score: 0.3533 - val_loss: 1.8912 - val_accuracy: 0.8662 - val_precision: 0.5796 - val_recall: 0.2314 - val_auc: 0.8034 - val_f1_score: 0.3301 - lr: 1.0000e-04\n",
      "Epoch 34/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.6055 - accuracy: 0.8750 - precision: 0.6727 - recall: 0.2440 - auc: 0.8316 - f1_score: 0.3570 - val_loss: 1.8748 - val_accuracy: 0.8658 - val_precision: 0.5741 - val_recall: 0.2343 - val_auc: 0.8060 - val_f1_score: 0.3303 - lr: 1.0000e-04\n",
      "Epoch 35/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.5966 - accuracy: 0.8744 - precision: 0.6610 - recall: 0.2478 - auc: 0.8320 - f1_score: 0.3596 - val_loss: 1.8788 - val_accuracy: 0.8676 - val_precision: 0.5823 - val_recall: 0.2597 - val_auc: 0.8049 - val_f1_score: 0.3579 - lr: 1.0000e-04\n",
      "Epoch 36/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.5831 - accuracy: 0.8752 - precision: 0.6684 - recall: 0.2510 - auc: 0.8339 - f1_score: 0.3638 - val_loss: 1.7167 - val_accuracy: 0.8765 - val_precision: 0.6683 - val_recall: 0.2694 - val_auc: 0.8346 - val_f1_score: 0.3809 - lr: 1.0000e-04\n",
      "Epoch 37/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 2.5466 - accuracy: 0.8761 - precision: 0.6711 - recall: 0.2606 - auc: 0.8374 - f1_score: 0.3741 - val_loss: 1.6854 - val_accuracy: 0.8768 - val_precision: 0.6716 - val_recall: 0.2699 - val_auc: 0.8415 - val_f1_score: 0.3815 - lr: 1.0000e-04\n",
      "Epoch 38/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.5487 - accuracy: 0.8767 - precision: 0.6769 - recall: 0.2619 - auc: 0.8381 - f1_score: 0.3766 - val_loss: 1.6958 - val_accuracy: 0.8758 - val_precision: 0.6550 - val_recall: 0.2758 - val_auc: 0.8381 - val_f1_score: 0.3871 - lr: 1.0000e-04\n",
      "Epoch 39/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.5095 - accuracy: 0.8758 - precision: 0.6670 - recall: 0.2606 - auc: 0.8394 - f1_score: 0.3737 - val_loss: 1.6517 - val_accuracy: 0.8783 - val_precision: 0.6758 - val_recall: 0.2849 - val_auc: 0.8463 - val_f1_score: 0.3989 - lr: 1.0000e-04\n",
      "Epoch 40/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.5180 - accuracy: 0.8767 - precision: 0.6739 - recall: 0.2658 - auc: 0.8407 - f1_score: 0.3800 - val_loss: 1.7025 - val_accuracy: 0.8738 - val_precision: 0.6400 - val_recall: 0.2660 - val_auc: 0.8327 - val_f1_score: 0.3750 - lr: 1.0000e-04\n",
      "Epoch 41/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.5057 - accuracy: 0.8769 - precision: 0.6765 - recall: 0.2646 - auc: 0.8411 - f1_score: 0.3791 - val_loss: 1.6441 - val_accuracy: 0.8784 - val_precision: 0.6744 - val_recall: 0.2880 - val_auc: 0.8456 - val_f1_score: 0.4010 - lr: 1.0000e-04\n",
      "Epoch 42/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.4654 - accuracy: 0.8777 - precision: 0.6810 - recall: 0.2713 - auc: 0.8441 - f1_score: 0.3871 - val_loss: 1.6700 - val_accuracy: 0.8760 - val_precision: 0.6570 - val_recall: 0.2757 - val_auc: 0.8383 - val_f1_score: 0.3885 - lr: 1.0000e-04\n",
      "Epoch 43/125\n",
      "449/449 [==============================] - 55s 121ms/step - loss: 2.4589 - accuracy: 0.8784 - precision: 0.6805 - recall: 0.2799 - auc: 0.8456 - f1_score: 0.3956 - val_loss: 1.6344 - val_accuracy: 0.8786 - val_precision: 0.6731 - val_recall: 0.2914 - val_auc: 0.8454 - val_f1_score: 0.4040 - lr: 1.0000e-04\n",
      "Epoch 44/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 2.4325 - accuracy: 0.8785 - precision: 0.6815 - recall: 0.2807 - auc: 0.8466 - f1_score: 0.3968 - val_loss: 1.6406 - val_accuracy: 0.8772 - val_precision: 0.6611 - val_recall: 0.2881 - val_auc: 0.8429 - val_f1_score: 0.3996 - lr: 1.0000e-04\n",
      "Epoch 45/125\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 2.4600 - accuracy: 0.8786 - precision: 0.6811 - recall: 0.2825 - auc: 0.8461 - f1_score: 0.3982 - val_loss: 1.6696 - val_accuracy: 0.8754 - val_precision: 0.6421 - val_recall: 0.2880 - val_auc: 0.8355 - val_f1_score: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 46/125\n",
      "449/449 [==============================] - 55s 123ms/step - loss: 2.4001 - accuracy: 0.8790 - precision: 0.6818 - recall: 0.2868 - auc: 0.8491 - f1_score: 0.4026 - val_loss: 1.6255 - val_accuracy: 0.8781 - val_precision: 0.6680 - val_recall: 0.2921 - val_auc: 0.8440 - val_f1_score: 0.4044 - lr: 1.0000e-04\n",
      "Epoch 47/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.3947 - accuracy: 0.8799 - precision: 0.6875 - recall: 0.2925 - auc: 0.8521 - f1_score: 0.4093 - val_loss: 1.6376 - val_accuracy: 0.8760 - val_precision: 0.6464 - val_recall: 0.2913 - val_auc: 0.8407 - val_f1_score: 0.4002 - lr: 1.0000e-04\n",
      "Epoch 48/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.3324 - accuracy: 0.8811 - precision: 0.6945 - recall: 0.2998 - auc: 0.8555 - f1_score: 0.4176 - val_loss: 1.6369 - val_accuracy: 0.8754 - val_precision: 0.6427 - val_recall: 0.2880 - val_auc: 0.8396 - val_f1_score: 0.3962 - lr: 1.0000e-04\n",
      "Epoch 49/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.3521 - accuracy: 0.8812 - precision: 0.6924 - recall: 0.3025 - auc: 0.8544 - f1_score: 0.4201 - val_loss: 1.6094 - val_accuracy: 0.8783 - val_precision: 0.6724 - val_recall: 0.2882 - val_auc: 0.8443 - val_f1_score: 0.3997 - lr: 1.0000e-04\n",
      "Epoch 50/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.3336 - accuracy: 0.8805 - precision: 0.6897 - recall: 0.2967 - auc: 0.8545 - f1_score: 0.4136 - val_loss: 1.5780 - val_accuracy: 0.8799 - val_precision: 0.6747 - val_recall: 0.3077 - val_auc: 0.8503 - val_f1_score: 0.4227 - lr: 1.0000e-04\n",
      "Epoch 51/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.3015 - accuracy: 0.8819 - precision: 0.6950 - recall: 0.3087 - auc: 0.8592 - f1_score: 0.4263 - val_loss: 1.5721 - val_accuracy: 0.8804 - val_precision: 0.6700 - val_recall: 0.3204 - val_auc: 0.8519 - val_f1_score: 0.4327 - lr: 1.0000e-04\n",
      "Epoch 52/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.2948 - accuracy: 0.8817 - precision: 0.6921 - recall: 0.3103 - auc: 0.8588 - f1_score: 0.4274 - val_loss: 1.5902 - val_accuracy: 0.8781 - val_precision: 0.6556 - val_recall: 0.3097 - val_auc: 0.8467 - val_f1_score: 0.4187 - lr: 1.0000e-04\n",
      "Epoch 53/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 2.2901 - accuracy: 0.8818 - precision: 0.6906 - recall: 0.3124 - auc: 0.8595 - f1_score: 0.4292 - val_loss: 1.5672 - val_accuracy: 0.8790 - val_precision: 0.6571 - val_recall: 0.3206 - val_auc: 0.8509 - val_f1_score: 0.4283 - lr: 1.0000e-04\n",
      "Epoch 54/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 2.2818 - accuracy: 0.8828 - precision: 0.6960 - recall: 0.3185 - auc: 0.8606 - f1_score: 0.4360 - val_loss: 1.5899 - val_accuracy: 0.8793 - val_precision: 0.6480 - val_recall: 0.3392 - val_auc: 0.8463 - val_f1_score: 0.4450 - lr: 1.0000e-04\n",
      "Epoch 55/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.2425 - accuracy: 0.8836 - precision: 0.6982 - recall: 0.3267 - auc: 0.8640 - f1_score: 0.4441 - val_loss: 1.5683 - val_accuracy: 0.8774 - val_precision: 0.6479 - val_recall: 0.3107 - val_auc: 0.8487 - val_f1_score: 0.4177 - lr: 1.0000e-04\n",
      "Epoch 56/125\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 2.2368 - accuracy: 0.8834 - precision: 0.6953 - recall: 0.3267 - auc: 0.8653 - f1_score: 0.4434 - val_loss: 1.5859 - val_accuracy: 0.8769 - val_precision: 0.6391 - val_recall: 0.3178 - val_auc: 0.8451 - val_f1_score: 0.4223 - lr: 1.0000e-04\n",
      "Epoch 57/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.2251 - accuracy: 0.8836 - precision: 0.6973 - recall: 0.3273 - auc: 0.8657 - f1_score: 0.4445 - val_loss: 1.6187 - val_accuracy: 0.8752 - val_precision: 0.6296 - val_recall: 0.3069 - val_auc: 0.8368 - val_f1_score: 0.4121 - lr: 1.0000e-04\n",
      "Epoch 58/125\n",
      "449/449 [==============================] - 55s 123ms/step - loss: 2.2222 - accuracy: 0.8830 - precision: 0.6921 - recall: 0.3262 - auc: 0.8649 - f1_score: 0.4424 - val_loss: 1.5810 - val_accuracy: 0.8762 - val_precision: 0.6354 - val_recall: 0.3125 - val_auc: 0.8437 - val_f1_score: 0.4160 - lr: 1.0000e-04\n",
      "Epoch 59/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.2320 - accuracy: 0.8838 - precision: 0.6981 - recall: 0.3289 - auc: 0.8652 - f1_score: 0.4458 - val_loss: 1.5843 - val_accuracy: 0.8766 - val_precision: 0.6339 - val_recall: 0.3221 - val_auc: 0.8427 - val_f1_score: 0.4240 - lr: 1.0000e-04\n",
      "Epoch 60/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 2.1869 - accuracy: 0.8853 - precision: 0.7030 - recall: 0.3411 - auc: 0.8695 - f1_score: 0.4584 - val_loss: 1.5740 - val_accuracy: 0.8762 - val_precision: 0.6289 - val_recall: 0.3260 - val_auc: 0.8444 - val_f1_score: 0.4291 - lr: 1.0000e-04\n",
      "Epoch 61/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 2.1685 - accuracy: 0.8857 - precision: 0.7029 - recall: 0.3458 - auc: 0.8705 - f1_score: 0.4626 - val_loss: 1.5521 - val_accuracy: 0.8784 - val_precision: 0.6474 - val_recall: 0.3267 - val_auc: 0.8482 - val_f1_score: 0.4337 - lr: 1.0000e-04\n",
      "Epoch 62/125\n",
      "449/449 [==============================] - 55s 121ms/step - loss: 2.1626 - accuracy: 0.8855 - precision: 0.7025 - recall: 0.3447 - auc: 0.8711 - f1_score: 0.4611 - val_loss: 1.5338 - val_accuracy: 0.8798 - val_precision: 0.6463 - val_recall: 0.3498 - val_auc: 0.8526 - val_f1_score: 0.4522 - lr: 1.0000e-04\n",
      "Epoch 63/125\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 2.1695 - accuracy: 0.8851 - precision: 0.6994 - recall: 0.3428 - auc: 0.8699 - f1_score: 0.4588 - val_loss: 1.5678 - val_accuracy: 0.8767 - val_precision: 0.6267 - val_recall: 0.3394 - val_auc: 0.8453 - val_f1_score: 0.4367 - lr: 1.0000e-04\n",
      "Epoch 64/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.1621 - accuracy: 0.8856 - precision: 0.7001 - recall: 0.3490 - auc: 0.8721 - f1_score: 0.4647 - val_loss: 1.5478 - val_accuracy: 0.8769 - val_precision: 0.6333 - val_recall: 0.3293 - val_auc: 0.8472 - val_f1_score: 0.4323 - lr: 1.0000e-04\n",
      "Epoch 65/125\n",
      "449/449 [==============================] - 56s 124ms/step - loss: 2.1361 - accuracy: 0.8865 - precision: 0.7070 - recall: 0.3506 - auc: 0.8733 - f1_score: 0.4678 - val_loss: 1.5104 - val_accuracy: 0.8803 - val_precision: 0.6506 - val_recall: 0.3509 - val_auc: 0.8555 - val_f1_score: 0.4540 - lr: 1.0000e-04\n",
      "Epoch 66/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 2.1116 - accuracy: 0.8873 - precision: 0.7082 - recall: 0.3588 - auc: 0.8757 - f1_score: 0.4753 - val_loss: 1.5459 - val_accuracy: 0.8764 - val_precision: 0.6318 - val_recall: 0.3227 - val_auc: 0.8468 - val_f1_score: 0.4273 - lr: 1.0000e-04\n",
      "Epoch 67/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.1158 - accuracy: 0.8868 - precision: 0.7045 - recall: 0.3579 - auc: 0.8752 - f1_score: 0.4736 - val_loss: 1.5170 - val_accuracy: 0.8781 - val_precision: 0.6379 - val_recall: 0.3399 - val_auc: 0.8525 - val_f1_score: 0.4428 - lr: 1.0000e-04\n",
      "Epoch 68/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.0973 - accuracy: 0.8870 - precision: 0.7044 - recall: 0.3605 - auc: 0.8769 - f1_score: 0.4759 - val_loss: 1.4875 - val_accuracy: 0.8804 - val_precision: 0.6530 - val_recall: 0.3472 - val_auc: 0.8580 - val_f1_score: 0.4522 - lr: 1.0000e-04\n",
      "Epoch 69/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.0614 - accuracy: 0.8887 - precision: 0.7150 - recall: 0.3678 - auc: 0.8793 - f1_score: 0.4846 - val_loss: 1.5564 - val_accuracy: 0.8762 - val_precision: 0.6174 - val_recall: 0.3509 - val_auc: 0.8462 - val_f1_score: 0.4477 - lr: 1.0000e-04\n",
      "Epoch 70/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 2.0651 - accuracy: 0.8887 - precision: 0.7114 - recall: 0.3715 - auc: 0.8794 - f1_score: 0.4872 - val_loss: 1.5371 - val_accuracy: 0.8782 - val_precision: 0.6323 - val_recall: 0.3519 - val_auc: 0.8490 - val_f1_score: 0.4520 - lr: 1.0000e-04\n",
      "Epoch 71/125\n",
      "449/449 [==============================] - 55s 124ms/step - loss: 2.0609 - accuracy: 0.8888 - precision: 0.7102 - recall: 0.3744 - auc: 0.8808 - f1_score: 0.4890 - val_loss: 1.4848 - val_accuracy: 0.8810 - val_precision: 0.6516 - val_recall: 0.3587 - val_auc: 0.8573 - val_f1_score: 0.4616 - lr: 1.0000e-04\n",
      "Epoch 72/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.0423 - accuracy: 0.8895 - precision: 0.7135 - recall: 0.3790 - auc: 0.8819 - f1_score: 0.4942 - val_loss: 1.4831 - val_accuracy: 0.8809 - val_precision: 0.6555 - val_recall: 0.3507 - val_auc: 0.8571 - val_f1_score: 0.4519 - lr: 1.0000e-04\n",
      "Epoch 73/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.0497 - accuracy: 0.8895 - precision: 0.7110 - recall: 0.3814 - auc: 0.8811 - f1_score: 0.4952 - val_loss: 1.4898 - val_accuracy: 0.8803 - val_precision: 0.6480 - val_recall: 0.3555 - val_auc: 0.8554 - val_f1_score: 0.4596 - lr: 1.0000e-04\n",
      "Epoch 74/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.0367 - accuracy: 0.8895 - precision: 0.7107 - recall: 0.3820 - auc: 0.8834 - f1_score: 0.4959 - val_loss: 1.5010 - val_accuracy: 0.8782 - val_precision: 0.6299 - val_recall: 0.3576 - val_auc: 0.8531 - val_f1_score: 0.4557 - lr: 1.0000e-04\n",
      "Epoch 75/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 2.0199 - accuracy: 0.8901 - precision: 0.7142 - recall: 0.3847 - auc: 0.8838 - f1_score: 0.4992 - val_loss: 1.4656 - val_accuracy: 0.8827 - val_precision: 0.6585 - val_recall: 0.3710 - val_auc: 0.8607 - val_f1_score: 0.4750 - lr: 1.0000e-04\n",
      "Epoch 76/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 2.0325 - accuracy: 0.8901 - precision: 0.7173 - recall: 0.3813 - auc: 0.8838 - f1_score: 0.4968 - val_loss: 1.4741 - val_accuracy: 0.8813 - val_precision: 0.6481 - val_recall: 0.3695 - val_auc: 0.8583 - val_f1_score: 0.4696 - lr: 1.0000e-04\n",
      "Epoch 77/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 2.0103 - accuracy: 0.8905 - precision: 0.7110 - recall: 0.3930 - auc: 0.8853 - f1_score: 0.5052 - val_loss: 1.4743 - val_accuracy: 0.8808 - val_precision: 0.6444 - val_recall: 0.3693 - val_auc: 0.8578 - val_f1_score: 0.4686 - lr: 1.0000e-04\n",
      "Epoch 78/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.9776 - accuracy: 0.8912 - precision: 0.7180 - recall: 0.3922 - auc: 0.8871 - f1_score: 0.5064 - val_loss: 1.5454 - val_accuracy: 0.8753 - val_precision: 0.6093 - val_recall: 0.3539 - val_auc: 0.8449 - val_f1_score: 0.4441 - lr: 1.0000e-04\n",
      "Epoch 79/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.9991 - accuracy: 0.8914 - precision: 0.7171 - recall: 0.3958 - auc: 0.8883 - f1_score: 0.5091 - val_loss: 1.5516 - val_accuracy: 0.8732 - val_precision: 0.6011 - val_recall: 0.3342 - val_auc: 0.8409 - val_f1_score: 0.4280 - lr: 1.0000e-04\n",
      "Epoch 80/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 1.9756 - accuracy: 0.8919 - precision: 0.7196 - recall: 0.3985 - auc: 0.8881 - f1_score: 0.5118 - val_loss: 1.4759 - val_accuracy: 0.8801 - val_precision: 0.6366 - val_recall: 0.3746 - val_auc: 0.8576 - val_f1_score: 0.4691 - lr: 1.0000e-04\n",
      "Epoch 81/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 1.9765 - accuracy: 0.8911 - precision: 0.7127 - recall: 0.3988 - auc: 0.8893 - f1_score: 0.5105 - val_loss: 1.4666 - val_accuracy: 0.8816 - val_precision: 0.6472 - val_recall: 0.3770 - val_auc: 0.8584 - val_f1_score: 0.4738 - lr: 1.0000e-04\n",
      "Epoch 82/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 1.9280 - accuracy: 0.8933 - precision: 0.7243 - recall: 0.4091 - auc: 0.8914 - f1_score: 0.5219 - val_loss: 1.4884 - val_accuracy: 0.8793 - val_precision: 0.6285 - val_recall: 0.3788 - val_auc: 0.8556 - val_f1_score: 0.4706 - lr: 1.0000e-04\n",
      "Epoch 83/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 1.9269 - accuracy: 0.8942 - precision: 0.7274 - recall: 0.4149 - auc: 0.8934 - f1_score: 0.5276 - val_loss: 1.4723 - val_accuracy: 0.8802 - val_precision: 0.6384 - val_recall: 0.3721 - val_auc: 0.8569 - val_f1_score: 0.4703 - lr: 1.0000e-04\n",
      "Epoch 84/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.9377 - accuracy: 0.8928 - precision: 0.7169 - recall: 0.4122 - auc: 0.8912 - f1_score: 0.5227 - val_loss: 1.4716 - val_accuracy: 0.8800 - val_precision: 0.6337 - val_recall: 0.3796 - val_auc: 0.8573 - val_f1_score: 0.4731 - lr: 1.0000e-04\n",
      "Epoch 85/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 1.9026 - accuracy: 0.8939 - precision: 0.7236 - recall: 0.4161 - auc: 0.8951 - f1_score: 0.5274 - val_loss: 1.4532 - val_accuracy: 0.8810 - val_precision: 0.6399 - val_recall: 0.3827 - val_auc: 0.8609 - val_f1_score: 0.4763 - lr: 1.0000e-04\n",
      "Epoch 86/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.9019 - accuracy: 0.8944 - precision: 0.7250 - recall: 0.4202 - auc: 0.8950 - f1_score: 0.5312 - val_loss: 1.4816 - val_accuracy: 0.8807 - val_precision: 0.6366 - val_recall: 0.3846 - val_auc: 0.8554 - val_f1_score: 0.4775 - lr: 1.0000e-04\n",
      "Epoch 87/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.9169 - accuracy: 0.8940 - precision: 0.7238 - recall: 0.4166 - auc: 0.8934 - f1_score: 0.5279 - val_loss: 1.4762 - val_accuracy: 0.8797 - val_precision: 0.6339 - val_recall: 0.3743 - val_auc: 0.8551 - val_f1_score: 0.4682 - lr: 1.0000e-04\n",
      "Epoch 88/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.9081 - accuracy: 0.8943 - precision: 0.7231 - recall: 0.4216 - auc: 0.8949 - f1_score: 0.5317 - val_loss: 1.5002 - val_accuracy: 0.8773 - val_precision: 0.6176 - val_recall: 0.3702 - val_auc: 0.8505 - val_f1_score: 0.4623 - lr: 1.0000e-04\n",
      "Epoch 89/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 1.9022 - accuracy: 0.8947 - precision: 0.7257 - recall: 0.4224 - auc: 0.8949 - f1_score: 0.5330 - val_loss: 1.4606 - val_accuracy: 0.8793 - val_precision: 0.6326 - val_recall: 0.3696 - val_auc: 0.8577 - val_f1_score: 0.4644 - lr: 1.0000e-04\n",
      "Epoch 90/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 1.8855 - accuracy: 0.8947 - precision: 0.7251 - recall: 0.4237 - auc: 0.8961 - f1_score: 0.5339 - val_loss: 1.5095 - val_accuracy: 0.8786 - val_precision: 0.6163 - val_recall: 0.3982 - val_auc: 0.8527 - val_f1_score: 0.4828 - lr: 1.0000e-04\n",
      "Epoch 91/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 1.8614 - accuracy: 0.8962 - precision: 0.7304 - recall: 0.4338 - auc: 0.8987 - f1_score: 0.5433 - val_loss: 1.4572 - val_accuracy: 0.8801 - val_precision: 0.6308 - val_recall: 0.3877 - val_auc: 0.8586 - val_f1_score: 0.4780 - lr: 1.0000e-04\n",
      "Epoch 92/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 1.8657 - accuracy: 0.8966 - precision: 0.7310 - recall: 0.4368 - auc: 0.8989 - f1_score: 0.5458 - val_loss: 1.4774 - val_accuracy: 0.8785 - val_precision: 0.6216 - val_recall: 0.3820 - val_auc: 0.8557 - val_f1_score: 0.4733 - lr: 1.0000e-04\n",
      "Epoch 93/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 1.8492 - accuracy: 0.8969 - precision: 0.7324 - recall: 0.4386 - auc: 0.8999 - f1_score: 0.5479 - val_loss: 1.4817 - val_accuracy: 0.8788 - val_precision: 0.6239 - val_recall: 0.3813 - val_auc: 0.8548 - val_f1_score: 0.4742 - lr: 1.0000e-04\n",
      "Epoch 94/125\n",
      "449/449 [==============================] - 52s 116ms/step - loss: 1.8516 - accuracy: 0.8964 - precision: 0.7287 - recall: 0.4381 - auc: 0.9000 - f1_score: 0.5461 - val_loss: 1.4727 - val_accuracy: 0.8807 - val_precision: 0.6296 - val_recall: 0.4012 - val_auc: 0.8570 - val_f1_score: 0.4894 - lr: 1.0000e-04\n",
      "Epoch 95/125\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.8530 - accuracy: 0.8959 - precision: 0.7255 - recall: 0.4363 - auc: 0.8996 - f1_score: 0.5440\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 1.8530 - accuracy: 0.8959 - precision: 0.7255 - recall: 0.4363 - auc: 0.8996 - f1_score: 0.5440 - val_loss: 1.4942 - val_accuracy: 0.8790 - val_precision: 0.6219 - val_recall: 0.3906 - val_auc: 0.8521 - val_f1_score: 0.4799 - lr: 1.0000e-04\n",
      "Epoch 96/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 1.7817 - accuracy: 0.8994 - precision: 0.7428 - recall: 0.4528 - auc: 0.9063 - f1_score: 0.5615 - val_loss: 1.4852 - val_accuracy: 0.8786 - val_precision: 0.6209 - val_recall: 0.3849 - val_auc: 0.8538 - val_f1_score: 0.4752 - lr: 5.0000e-05\n",
      "Epoch 97/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 1.7591 - accuracy: 0.8999 - precision: 0.7412 - recall: 0.4604 - auc: 0.9082 - f1_score: 0.5673 - val_loss: 1.4515 - val_accuracy: 0.8809 - val_precision: 0.6279 - val_recall: 0.4083 - val_auc: 0.8614 - val_f1_score: 0.4921 - lr: 5.0000e-05\n",
      "Epoch 98/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 1.7351 - accuracy: 0.9020 - precision: 0.7497 - recall: 0.4719 - auc: 0.9105 - f1_score: 0.5784 - val_loss: 1.4750 - val_accuracy: 0.8790 - val_precision: 0.6171 - val_recall: 0.4035 - val_auc: 0.8572 - val_f1_score: 0.4862 - lr: 5.0000e-05\n",
      "Epoch 99/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 1.7238 - accuracy: 0.9015 - precision: 0.7430 - recall: 0.4745 - auc: 0.9112 - f1_score: 0.5783 - val_loss: 1.4528 - val_accuracy: 0.8815 - val_precision: 0.6299 - val_recall: 0.4131 - val_auc: 0.8610 - val_f1_score: 0.4979 - lr: 5.0000e-05\n",
      "Epoch 100/125\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 1.7390 - accuracy: 0.9017 - precision: 0.7419 - recall: 0.4788 - auc: 0.9114 - f1_score: 0.5814 - val_loss: 1.4697 - val_accuracy: 0.8793 - val_precision: 0.6179 - val_recall: 0.4062 - val_auc: 0.8586 - val_f1_score: 0.4885 - lr: 5.0000e-05\n",
      "Epoch 101/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 1.7048 - accuracy: 0.9029 - precision: 0.7505 - recall: 0.4797 - auc: 0.9135 - f1_score: 0.5843 - val_loss: 1.4589 - val_accuracy: 0.8798 - val_precision: 0.6203 - val_recall: 0.4083 - val_auc: 0.8603 - val_f1_score: 0.4944 - lr: 5.0000e-05\n",
      "Epoch 102/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 1.7143 - accuracy: 0.9021 - precision: 0.7440 - recall: 0.4800 - auc: 0.9126 - f1_score: 0.5829 - val_loss: 1.4462 - val_accuracy: 0.8811 - val_precision: 0.6270 - val_recall: 0.4135 - val_auc: 0.8624 - val_f1_score: 0.4978 - lr: 5.0000e-05\n",
      "Epoch 103/125\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 1.6982 - accuracy: 0.9027 - precision: 0.7466 - recall: 0.4829 - auc: 0.9138 - f1_score: 0.5855 - val_loss: 1.4505 - val_accuracy: 0.8816 - val_precision: 0.6285 - val_recall: 0.4184 - val_auc: 0.8619 - val_f1_score: 0.5036 - lr: 5.0000e-05\n",
      "Epoch 104/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.6742 - accuracy: 0.9033 - precision: 0.7464 - recall: 0.4896 - auc: 0.9157 - f1_score: 0.5906 - val_loss: 1.4476 - val_accuracy: 0.8806 - val_precision: 0.6233 - val_recall: 0.4156 - val_auc: 0.8629 - val_f1_score: 0.4974 - lr: 5.0000e-05\n",
      "Epoch 105/125\n",
      "449/449 [==============================] - 55s 123ms/step - loss: 1.6880 - accuracy: 0.9040 - precision: 0.7501 - recall: 0.4918 - auc: 0.9153 - f1_score: 0.5931 - val_loss: 1.4714 - val_accuracy: 0.8801 - val_precision: 0.6215 - val_recall: 0.4101 - val_auc: 0.8584 - val_f1_score: 0.4936 - lr: 5.0000e-05\n",
      "Epoch 106/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 1.6821 - accuracy: 0.9042 - precision: 0.7497 - recall: 0.4948 - auc: 0.9162 - f1_score: 0.5955 - val_loss: 1.4776 - val_accuracy: 0.8785 - val_precision: 0.6141 - val_recall: 0.4015 - val_auc: 0.8564 - val_f1_score: 0.4850 - lr: 5.0000e-05\n",
      "Epoch 107/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 1.6826 - accuracy: 0.9041 - precision: 0.7467 - recall: 0.4974 - auc: 0.9159 - f1_score: 0.5961 - val_loss: 1.4511 - val_accuracy: 0.8817 - val_precision: 0.6256 - val_recall: 0.4285 - val_auc: 0.8634 - val_f1_score: 0.5056 - lr: 5.0000e-05\n",
      "Epoch 108/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 1.6549 - accuracy: 0.9049 - precision: 0.7525 - recall: 0.4985 - auc: 0.9179 - f1_score: 0.5989 - val_loss: 1.4472 - val_accuracy: 0.8819 - val_precision: 0.6255 - val_recall: 0.4323 - val_auc: 0.8646 - val_f1_score: 0.5105 - lr: 5.0000e-05\n",
      "Epoch 109/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.6529 - accuracy: 0.9052 - precision: 0.7528 - recall: 0.5004 - auc: 0.9184 - f1_score: 0.6002 - val_loss: 1.4678 - val_accuracy: 0.8810 - val_precision: 0.6235 - val_recall: 0.4224 - val_auc: 0.8599 - val_f1_score: 0.5011 - lr: 5.0000e-05\n",
      "Epoch 110/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 1.6344 - accuracy: 0.9047 - precision: 0.7501 - recall: 0.4995 - auc: 0.9196 - f1_score: 0.5988 - val_loss: 1.4751 - val_accuracy: 0.8791 - val_precision: 0.6134 - val_recall: 0.4156 - val_auc: 0.8584 - val_f1_score: 0.4937 - lr: 5.0000e-05\n",
      "Epoch 111/125\n",
      "449/449 [==============================] - 55s 122ms/step - loss: 1.6389 - accuracy: 0.9058 - precision: 0.7532 - recall: 0.5069 - auc: 0.9195 - f1_score: 0.6054 - val_loss: 1.4692 - val_accuracy: 0.8805 - val_precision: 0.6206 - val_recall: 0.4209 - val_auc: 0.8588 - val_f1_score: 0.5008 - lr: 5.0000e-05\n",
      "Epoch 112/125\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.6235 - accuracy: 0.9069 - precision: 0.7577 - recall: 0.5118 - auc: 0.9202 - f1_score: 0.6102\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 1.6235 - accuracy: 0.9069 - precision: 0.7577 - recall: 0.5118 - auc: 0.9202 - f1_score: 0.6102 - val_loss: 1.4582 - val_accuracy: 0.8805 - val_precision: 0.6192 - val_recall: 0.4244 - val_auc: 0.8616 - val_f1_score: 0.5023 - lr: 5.0000e-05\n",
      "Epoch 113/125\n",
      "449/449 [==============================] - 53s 119ms/step - loss: 1.5997 - accuracy: 0.9077 - precision: 0.7607 - recall: 0.5168 - auc: 0.9233 - f1_score: 0.6148 - val_loss: 1.4617 - val_accuracy: 0.8799 - val_precision: 0.6166 - val_recall: 0.4210 - val_auc: 0.8609 - val_f1_score: 0.4984 - lr: 2.5000e-05\n",
      "Epoch 114/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 1.5908 - accuracy: 0.9078 - precision: 0.7614 - recall: 0.5169 - auc: 0.9232 - f1_score: 0.6149 - val_loss: 1.4534 - val_accuracy: 0.8806 - val_precision: 0.6186 - val_recall: 0.4284 - val_auc: 0.8628 - val_f1_score: 0.5058 - lr: 2.5000e-05\n",
      "Epoch 115/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.5763 - accuracy: 0.9085 - precision: 0.7621 - recall: 0.5224 - auc: 0.9242 - f1_score: 0.6191 - val_loss: 1.4517 - val_accuracy: 0.8817 - val_precision: 0.6245 - val_recall: 0.4309 - val_auc: 0.8629 - val_f1_score: 0.5079 - lr: 2.5000e-05\n",
      "Epoch 116/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 1.5710 - accuracy: 0.9085 - precision: 0.7597 - recall: 0.5257 - auc: 0.9250 - f1_score: 0.6207 - val_loss: 1.4566 - val_accuracy: 0.8805 - val_precision: 0.6178 - val_recall: 0.4296 - val_auc: 0.8621 - val_f1_score: 0.5058 - lr: 2.5000e-05\n",
      "Epoch 117/125\n",
      "449/449 [==============================] - 53s 117ms/step - loss: 1.5683 - accuracy: 0.9086 - precision: 0.7625 - recall: 0.5230 - auc: 0.9249 - f1_score: 0.6195 - val_loss: 1.4568 - val_accuracy: 0.8807 - val_precision: 0.6183 - val_recall: 0.4303 - val_auc: 0.8626 - val_f1_score: 0.5064 - lr: 2.5000e-05\n",
      "Epoch 118/125\n",
      "449/449 [==============================] - 53s 118ms/step - loss: 1.5847 - accuracy: 0.9089 - precision: 0.7633 - recall: 0.5249 - auc: 0.9246 - f1_score: 0.6211 - val_loss: 1.4641 - val_accuracy: 0.8808 - val_precision: 0.6181 - val_recall: 0.4327 - val_auc: 0.8616 - val_f1_score: 0.5071 - lr: 2.5000e-05\n",
      "Epoch 119/125\n",
      "449/449 [==============================] - 54s 121ms/step - loss: 1.5570 - accuracy: 0.9095 - precision: 0.7631 - recall: 0.5313 - auc: 0.9263 - f1_score: 0.6254 - val_loss: 1.4613 - val_accuracy: 0.8805 - val_precision: 0.6164 - val_recall: 0.4331 - val_auc: 0.8624 - val_f1_score: 0.5062 - lr: 2.5000e-05\n",
      "Epoch 120/125\n",
      "449/449 [==============================] - 54s 120ms/step - loss: 1.5706 - accuracy: 0.9093 - precision: 0.7632 - recall: 0.5294 - auc: 0.9253 - f1_score: 0.6244 - val_loss: 1.4563 - val_accuracy: 0.8804 - val_precision: 0.6153 - val_recall: 0.4347 - val_auc: 0.8632 - val_f1_score: 0.5057 - lr: 2.5000e-05\n",
      "Epoch 121/125\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 1.5634 - accuracy: 0.9089 - precision: 0.7586 - recall: 0.5314 - auc: 0.9258 - f1_score: 0.6244 - val_loss: 1.4669 - val_accuracy: 0.8796 - val_precision: 0.6112 - val_recall: 0.4312 - val_auc: 0.8607 - val_f1_score: 0.5057 - lr: 2.5000e-05\n",
      "Epoch 122/125\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.5427 - accuracy: 0.9100 - precision: 0.7650 - recall: 0.5337 - auc: 0.9276 - f1_score: 0.6280\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "449/449 [==============================] - 54s 119ms/step - loss: 1.5427 - accuracy: 0.9100 - precision: 0.7650 - recall: 0.5337 - auc: 0.9276 - f1_score: 0.6280 - val_loss: 1.4540 - val_accuracy: 0.8813 - val_precision: 0.6207 - val_recall: 0.4345 - val_auc: 0.8636 - val_f1_score: 0.5100 - lr: 2.5000e-05\n",
      "Epoch 122: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Run Model\n",
    "\n",
    "counter = Counter(train_dataset.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : round(max_val/num_images,2) for class_id, num_images in counter.items()}  \n",
    "\n",
    "lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = PATIENCE,verbose = 1,factor = 0.50, min_lr = 1e-10)\n",
    "mcp = ModelCheckpoint('model.h5')\n",
    "es = EarlyStopping(verbose=1, patience=20)\n",
    "\n",
    "history=model.fit(train_dataset,\n",
    "                  validation_data=test_dataset,\n",
    "                  epochs = EPOCHS,\n",
    "                  verbose =1,\n",
    "                  callbacks = [lrd,mcp,es], \n",
    "                  class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 218s 486ms/step - loss: 0.9358 - accuracy: 0.9207 - precision: 0.8166 - recall: 0.5738 - auc: 0.9452 - f1_score: 0.6730\n",
      "113/113 [==============================] - 34s 303ms/step - loss: 1.4540 - accuracy: 0.8813 - precision: 0.6207 - recall: 0.4345 - auc: 0.8636 - f1_score: 0.5087\n"
     ]
    }
   ],
   "source": [
    "train_evalation = model.evaluate(train_dataset)\n",
    "test_evaluation = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_Enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
